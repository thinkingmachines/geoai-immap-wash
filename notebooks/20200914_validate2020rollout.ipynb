{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates 2020 predictions for urban and rural areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from shapely.wkt import loads\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../utils')\n",
    "from settings import *\n",
    "import geoutils\n",
    "import modelutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_satellite_features(gdf, year = 2018):\n",
    "    '''\n",
    "    Generates features derived from satellite images by piercing through rasters using the centroids of the grid from gdf\n",
    "    \n",
    "    Args\n",
    "        gdf (GeoDataFrame): indicator labelled grid\n",
    "    Returns\n",
    "        gdf (GeoDataFrame): indicator labelled grid with features\n",
    "    '''\n",
    "    # satellite image derived - pierce through rasters\n",
    "    geom_col = 'centroid_geometry'\n",
    "    satellite_features_ = satellite_features + ['nearest_highway']\n",
    "    pois_ = ['waterway', 'commercial', 'restaurant', 'hospital', 'airport']\n",
    "    poi_features_ = ['clipped_nearest_' + poi for poi in pois_]\n",
    "    for feature in tqdm(poi_features_ + satellite_features_):\n",
    "        if feature in satellite_features_:\n",
    "            tif_file = feats_dir + f'{year}_{area}_{feature}.tif'\n",
    "        else:\n",
    "            tif_file = feats_dir + f'2018_{area}_{feature}.tif'\n",
    "        raster = rio.open(tif_file)\n",
    "\n",
    "        # Perform point sampling\n",
    "        pxl = []\n",
    "        for index, row in gdf.iterrows():\n",
    "            for val in raster.sample([(row[geom_col].x, row[geom_col].y)]):\n",
    "                pxl.append(val[0])\n",
    "\n",
    "        # Add column to geodataframe\n",
    "        col_name = feature.replace('clipped_','')\n",
    "        gdf[col_name] = pxl\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp gs://immap-wash-training/grid/grids_in_urban_and_rural_areas.csv {data_dir}\n",
    "# !gsutil cp gs://immap-wash-training/features/2020_*.tif {feats_dir}\n",
    "# !gsutil cp gs://immap-wash-training/features/2018_colombia_aridity_cgiarv2.tif {feats_dir}2020_colombia_aridity_cgiarv2.tif\n",
    "# !gsutil cp gs://immap-wash-training/features/2018_colombia_nearest_highway.tif {feats_dir}2020_colombia_nearest_highway.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.read_csv(data_dir + 'grids_in_urban_and_rural_areas.csv')\n",
    "      .sort_values(by = 'urbanity')\n",
    "      .drop_duplicates(subset = 'id', keep = 'last'))\n",
    "geom_col = 'centroid_geometry'\n",
    "df[geom_col] = df[geom_col].apply(loads)\n",
    "gdf = gpd.GeoDataFrame(df, geometry = geom_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data for 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67218, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pixelated_urban_area_id</th>\n",
       "      <th>id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>urbanity</th>\n",
       "      <th>centroid_geometry</th>\n",
       "      <th>adm1_name</th>\n",
       "      <th>adm2_name</th>\n",
       "      <th>nearest_waterway</th>\n",
       "      <th>nearest_commercial</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_aridity_cgiarv2</th>\n",
       "      <th>lag_temperature</th>\n",
       "      <th>lag_nighttime_lights</th>\n",
       "      <th>lag_population</th>\n",
       "      <th>lag_elevation</th>\n",
       "      <th>lag_urban_index</th>\n",
       "      <th>lag_nearest_highway</th>\n",
       "      <th>nighttime_lights_area_mean</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25303605</td>\n",
       "      <td>POLYGON ((-74.4618779023438 5.4985334602661, -...</td>\n",
       "      <td>r</td>\n",
       "      <td>POINT (-74.4607517772487 5.49740733543157)</td>\n",
       "      <td>cundinamarca</td>\n",
       "      <td>caparrapi</td>\n",
       "      <td>1408.745117</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.460752</td>\n",
       "      <td>5.497407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25272300</td>\n",
       "      <td>POLYGON ((-74.47088690234379 5.4827677102661, ...</td>\n",
       "      <td>r</td>\n",
       "      <td>POINT (-74.469760777254 5.48164158547759)</td>\n",
       "      <td>cundinamarca</td>\n",
       "      <td>caparrapi</td>\n",
       "      <td>2134.792480</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.469761</td>\n",
       "      <td>5.481642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21837755</td>\n",
       "      <td>POLYGON ((-75.45962465234379 1.0976369602661, ...</td>\n",
       "      <td>r</td>\n",
       "      <td>POINT (-75.4584985274804 1.09651083525103)</td>\n",
       "      <td>caquet</td>\n",
       "      <td>milan</td>\n",
       "      <td>3844.412842</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-75.458499</td>\n",
       "      <td>1.096511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  pixelated_urban_area_id        id  \\\n",
       "0           0                      NaN  25303605   \n",
       "1           1                      NaN  25272300   \n",
       "2           2                      NaN  21837755   \n",
       "\n",
       "                                            geometry urbanity  \\\n",
       "0  POLYGON ((-74.4618779023438 5.4985334602661, -...        r   \n",
       "1  POLYGON ((-74.47088690234379 5.4827677102661, ...        r   \n",
       "2  POLYGON ((-75.45962465234379 1.0976369602661, ...        r   \n",
       "\n",
       "                            centroid_geometry     adm1_name  adm2_name  \\\n",
       "0  POINT (-74.4607517772487 5.49740733543157)  cundinamarca  caparrapi   \n",
       "1   POINT (-74.469760777254 5.48164158547759)  cundinamarca  caparrapi   \n",
       "2  POINT (-75.4584985274804 1.09651083525103)        caquet      milan   \n",
       "\n",
       "   nearest_waterway  nearest_commercial  ...  lag_aridity_cgiarv2  \\\n",
       "0       1408.745117             40000.0  ...                  NaN   \n",
       "1       2134.792480             40000.0  ...                  NaN   \n",
       "2       3844.412842             40000.0  ...                  NaN   \n",
       "\n",
       "   lag_temperature  lag_nighttime_lights  lag_population  lag_elevation  \\\n",
       "0              NaN                   NaN             NaN            NaN   \n",
       "1              NaN                   NaN             NaN            NaN   \n",
       "2              NaN                   NaN             NaN            NaN   \n",
       "\n",
       "   lag_urban_index  lag_nearest_highway  nighttime_lights_area_mean  \\\n",
       "0              NaN                  NaN                         NaN   \n",
       "1              NaN                  NaN                         NaN   \n",
       "2              NaN                  NaN                         NaN   \n",
       "\n",
       "           x         y  \n",
       "0 -74.460752  5.497407  \n",
       "1 -74.469761  5.481642  \n",
       "2 -75.458499  1.096511  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gdf = generate_satellite_features(gdf, year = 2020)\n",
    "# test_df = geoutils.generate_training_data(gdf)\n",
    "# cols = ['id', 'geometry'] + poi_features + satellite_features\n",
    "# print(test_df.shape)\n",
    "# test_df = test_df.dropna(subset = cols)\n",
    "# print('Complete cases %: ' + str(test_df.dropna(subset = cols).shape[0]/test_df.shape[0]*100))\n",
    "# test_df.to_csv(data_dir + '20200914_dataset_2020.csv')\n",
    "test_df = pd.read_csv(data_dir + '20200914_dataset_2020.csv')\n",
    "print(test_df.shape)\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train full model on 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57143, 45)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(data_dir + '20200830_dataset.csv')\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def model(train_df, test_df):\n",
    "    global clf\n",
    "    clf = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    feats = []\n",
    "    for indicator in tqdm(indicators[0:1]):\n",
    "\n",
    "        avg_metrics = {'correlation':[], 'r2':[], 'mae':[], 'rmse':[]}\n",
    "        X_train, y_train = train_df[features], train_df[indicator]\n",
    "        X_test = test_df[features]\n",
    "        scaler = RobustScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # clf = joblib.load(model_dir + 'model_' + indicator + '_2018_250m.pkl')\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        test_df['pred_' + indicator] = y_pred\n",
    "        \n",
    "        feature_importances = pd.DataFrame({'feature': list(train_df[features].columns)\n",
    "                                            , 'importance': list(clf.feature_importances_)})\n",
    "        top_features = (feature_importances\n",
    "                            .sort_values(by=['importance'], ascending = False))\n",
    "        top_features['indicator'] = indicator\n",
    "        feats.append(top_features)\n",
    "        \n",
    "#         joblib.dump(clf, model_dir + 'model_' + indicator + '_2018_250m.pkl')\n",
    "    \n",
    "    joblib.dump(scaler, scaler_dir + 'scaler_2018_250m.pkl')\n",
    "    \n",
    "    return test_df, pd.concat(feats, axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:00<00:00, 60.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# test_df, top_features = model(train_df, test_df)\n",
    "# top_features.to_csv('top_features_2018.csv', index = False)\n",
    "# test_df.to_csv(data_dir + '20200914_predictions2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load(scaler_dir + 'scaler_2018_250m.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_level = 'adm1_name'\n",
    "keep_cols = [agg_level] + features + indicators\n",
    "\n",
    "def clean_name(text):\n",
    "    return re.sub('[^a-z ]','', text.lower()).replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(data_dir + '20200830_dataset.csv').drop_duplicates('id')\n",
    "raw['adm1_name'] = raw['adm1_name'].apply(clean_name)\n",
    "\n",
    "feats_2020 = pd.read_csv(data_dir + '20200914_dataset_2020.csv')\n",
    "preds_2020 = pd.read_csv(data_dir + '20200914_predictions2020.csv').rename(columns = {\n",
    "    'pred_perc_hh_no_water_supply': 'perc_hh_no_water_supply',\n",
    "    'pred_perc_hh_no_toilet': 'perc_hh_no_toilet',\n",
    "    'pred_perc_hh_no_sewage': 'perc_hh_no_sewage',\n",
    "})[['id', 'perc_hh_no_water_supply', 'perc_hh_no_toilet', 'perc_hh_no_sewage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adm1_name</th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>vichada</td>\n",
       "      <td>perc_hh_no_water_supply</td>\n",
       "      <td>0.176869</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>vichada</td>\n",
       "      <td>perc_hh_no_toilet</td>\n",
       "      <td>0.078483</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>vichada</td>\n",
       "      <td>perc_hh_no_sewage</td>\n",
       "      <td>0.722966</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     adm1_name                  feature     value  year\n",
       "1053   vichada  perc_hh_no_water_supply  0.176869  2020\n",
       "1054   vichada        perc_hh_no_toilet  0.078483  2020\n",
       "1055   vichada        perc_hh_no_sewage  0.722966  2020"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join\n",
    "wash_grid_2018_ = raw\n",
    "wash_grid_2020_ = pd.merge(feats_2020, preds_2020, on = 'id')\n",
    "\n",
    "print(wash_grid_2018_.shape)\n",
    "print(wash_grid_2020_.shape)\n",
    "# filter to 2018 grids only for comparability\n",
    "wash_grid_2020_ = wash_grid_2020_[wash_grid_2020_['id'].isin(list(wash_grid_2018_['id'].unique()))]\n",
    "print(wash_grid_2020_.shape)\n",
    "\n",
    "# scale features except population\n",
    "wash_grid_2018 = wash_grid_2018_[keep_cols].copy()\n",
    "wash_grid_2020 = wash_grid_2020_[keep_cols].copy()\n",
    "\n",
    "wash_grid_2018.loc[:,features] = scaler.transform(wash_grid_2018[features])\n",
    "wash_grid_2020.loc[:,features] = scaler.transform(wash_grid_2020[features])\n",
    "\n",
    "wash_grid_2018['population'] = wash_grid_2018_['population']\n",
    "wash_grid_2020['population'] = wash_grid_2020_['population']\n",
    "\n",
    "# standardize naming\n",
    "to_replace = {'laguajira': 'la_guajira','valledelcauca': 'valle_del_cauca'}\n",
    "wash_grid_2018['adm1_name'] = wash_grid_2018['adm1_name'].replace(to_replace)\n",
    "wash_grid_2020['adm1_name'] = wash_grid_2020['adm1_name'].replace(to_replace)\n",
    "\n",
    "# get median for everything except population\n",
    "agg_type = {\n",
    "    'vegetation': 'median',\n",
    "    'aridity_cgiarv2': 'median',\n",
    "    'temperature': 'median',\n",
    "    'nighttime_lights': 'median',\n",
    "    'population': 'sum', ###\n",
    "    'elevation': 'median',\n",
    "    'urban_index': 'median',\n",
    "    'nearest_waterway': 'median',\n",
    "    'nearest_commercial': 'median',\n",
    "    'nearest_restaurant': 'median',\n",
    "    'nearest_hospital': 'median',\n",
    "    'nearest_airport': 'median',\n",
    "    'nearest_highway': 'median',\n",
    "    'perc_hh_no_water_supply': 'median',\n",
    "    'perc_hh_no_toilet': 'median',\n",
    "    'perc_hh_no_sewage': 'median',\n",
    "}\n",
    "wash_metro_2018 = wash_grid_2018.groupby(agg_level).agg(agg_type).reset_index()\n",
    "wash_metro_2020 = wash_grid_2020.groupby(agg_level).agg(agg_type).reset_index()\n",
    "\n",
    "# combine (wide format)\n",
    "wash_agg = pd.merge(\n",
    "    wash_metro_2018, wash_metro_2020, left_on = agg_level, right_on = agg_level, suffixes = ['', '_2020']\n",
    "    , how = 'left'\n",
    ")\n",
    "\n",
    "# convert to long\n",
    "df_ = wash_agg.set_index('adm1_name').stack().reset_index()\n",
    "df_.columns = ['adm1_name', 'feature', 'value']\n",
    "df_['year'] = 2018\n",
    "for i, row in df_.iterrows():\n",
    "    if row.feature[-5:] == '_2020':\n",
    "        df_.loc[i, 'year'] = 2020\n",
    "        df_.loc[i, 'feature'] = df_.loc[i, 'feature'][:-5]\n",
    "\n",
    "df_.to_csv('wash_agg.csv', index = False)\n",
    "df_.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vegetation                          0.123851\n",
       "aridity_cgiarv2                     0.123958\n",
       "temperature                         0.091185\n",
       "nighttime_lights                   -0.081389\n",
       "population                      38136.793795\n",
       "elevation                          -0.403423\n",
       "urban_index                        -0.366667\n",
       "nearest_waterway                    0.101871\n",
       "nearest_commercial                  0.161975\n",
       "nearest_restaurant                  0.064027\n",
       "nearest_hospital                    0.086090\n",
       "nearest_airport                    -0.019912\n",
       "nearest_highway                     0.067636\n",
       "perc_hh_no_water_supply             0.006579\n",
       "perc_hh_no_toilet                   0.012558\n",
       "perc_hh_no_sewage                   0.038235\n",
       "vegetation_2020                    -0.004327\n",
       "aridity_cgiarv2_2020                0.116220\n",
       "temperature_2020                    0.213526\n",
       "nighttime_lights_2020              -0.075808\n",
       "population_2020                 47619.434995\n",
       "elevation_2020                     -0.402200\n",
       "urban_index_2020                   -0.433333\n",
       "nearest_waterway_2020               0.093855\n",
       "nearest_commercial_2020             0.148891\n",
       "nearest_restaurant_2020             0.075859\n",
       "nearest_hospital_2020               0.100950\n",
       "nearest_airport_2020                0.374163\n",
       "nearest_highway_2020                0.038834\n",
       "perc_hh_no_water_supply_2020        0.052655\n",
       "perc_hh_no_toilet_2020              0.041874\n",
       "perc_hh_no_sewage_2020              0.134644\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wash_agg.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
